---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.0
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python tags=c()}
import numpy as np
import torch
from torchvision import models
from torchvision import transforms
from pathlib import Path
from tqdm import tqdm

import DatasetHandler as dh
import pooling
import regression as reg
import SFVQA as sfv
import VideoUtility as vu
```

```{python tags=c()}
def get_videoset_features(model, device, video_list: str, video_path: str, transform, 
                          dataset: str = 'LIVE', *, layers, frame_diff=False) -> list:
    '''Get the VQA dataset video names and scores, set a feature extractor model,
       get frames of each video, then get features of each frame in videos
       
    :param video_list: list of video sequences name
    :param video_path: videos' directory
    :param transform: preprocessing pipeline
    :param dataset: name of the VQA dataset to extract the features from
    :param fine_tune: use fine-tuned model if True
    :return: videos' frames features of dimension and videos scores (DMOS)
    '''
       
    # Convert the path string to a pathlib object
    video_path = Path(video_path)
    dataset = dataset.lower()
    # videos_frame_features = []
    for seq in tqdm(video_list):
        # Concatenate the video sequence name to the video directory to get the full video path
        vid_path = str(video_path / seq)
        if dataset == 'live':
            # Get frames of the video of the dimension 768 * 432 (LIVE VQA videos)
            vid_frames = vu.get_frames(vid_path, height=432, width=768)
        elif dataset == 'konvid1k':
            vid_frames = vu.get_frames(vid_path, frame_diff=frame_diff)
        # Get the features of all frames of the video
        frames_features = sfv.get_video_style_features(vid_frames, model, device, transform, layers)
        frames_features = np.array(frames_features)
        # videos_frame_features.append(frames_features)
        yield frames_features
    
    # return videos_frame_features, scores
```

```{python}
def init_vqa(model_name, vqa_dataset):
    ''' Set the frame feature extractor model, VQA dataset and frame size
    
    :param model_name: name of the feature extractor model, 'inceptionv3', 'vgg19':
    :param vqa_dataset: VQA dataset to evaluate the method on, 'KONVID1K' , 'LIVE'
    :return: model, fataset and frame size and patch
    '''
    
    if model_name == 'vgg19':
        frame_size, center_crop = 255, 224
        # Specify the layers to get style features from vgg19
        layers = {
                  # '0': 'conv1_1',
                  '5': 'conv2_1', 
                  # '10': 'conv3_1', 
                  # '19': 'conv4_1',
                  # '20': 'conv4_2',  
                  # '28': 'conv5_1'
                  }
        # Layer for getting features from frame differences
        diff_layer = {'20': 'conv4_2'}
        
    elif model_name == 'inceptionv3':
        frame_size, center_crop = 338, 299
        # Specify the layers to get style features from inceptionv3
        layers = {
                  # 'Conv2d_1a_3x3': 'conv1_1',
                  # 'Conv2d_3b_1x1': 'conv2_1', 
                  'Mixed_5b': 'Mixed_1', 
                  # 'Mixed_5c': 'Mixed_2',
                  'avgpool': 'avgpool'
                  }
        # Layer for getting features from frame differences
        diff_layer = {'avgpool': 'avgpool'}
        
    
    # Specify whether or not extract features from frame differences
    frame_diff = False
                
    return model_name, vqa_dataset, frame_size, center_crop, layers, diff_layer, frame_diff
    
```

```{python}
# Entry point of the program
def main():
    '''Run the whole process of VQA
    :param mode: 'save' if features have not already been extracted, 'load' otherwise
    '''
    # Initialize the vqa
    extractor_model, vqa_dataset, frame_size, center_crop, layers,\
                                    diff_layer, frame_diff = init_vqa('inceptionv3', 'konvid1k')
    # Get the list of videos and corresponding scores and preprocessing module
    video_list, scores, transform, video_path = dh.get_videoset_info(dataset=vqa_dataset,
                                                                     frame_size=frame_size,
                                                                     center_crop=center_crop)
    # Check if there is a GPU
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    # Set the frame features extractor model (VGG19)
    model = sfv.set_sf_model(device, fine_tune=False, model_name=extractor_model,
                             frame_size=frame_size, center_crop=center_crop)
    
    # -----------------------------------Frames---------------------------------------------*
    # Get frame features of all videos in the dataset --------------------------------------*
    videos_feats = get_videoset_features(model, device, video_list, video_path, transform,
                                             vqa_dataset, layers=layers)
    # Pool the frame level features to get video level features
    pooled_features = pooling.simple_pooling(videos_feats, pooling='max')
    
    # -------------------------------Frames Differences-------------------------------------*
    if frame_diff:
        # Get frame differences features of all videos in the dataset-----------------------*
        diff_feats = get_videoset_features(model, device, video_list, video_path, transform,
                                                 vqa_dataset, layers=diff_layer, frame_diff=frame_diff)
        # Pool the frame differences features to get video level difference features
        pooled_diff = pooling.simple_pooling(diff_feats, pooling='max')
        # Concatenate the pooled features from frames and frame differences
        pooled_features = np.concatenate((pooled_features, pooled_diff), axis=1)   
    
    # Train a regressor using video level features and indicate how well it predicts the scores
    # using various correlations
    reg.regression(pooled_features, scores, regression_method='svr', dataset=vqa_dataset)               
```

```{python tags=c()}
# Run the main function if current file is the script, not a module
if __name__ == "__main__":
    main()
```

```{python}

```

```{python}

```

```{python}

```

```{python}

```
