---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.13.8
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python tags=c()}
import numpy as np
import torch
from torchvision import models
from torchvision import transforms
from pathlib import Path

import DatasetHandler as dh
import pooling
import regression as reg
import SFVQA as sfv
import VideoUtility as vu
```

```{python tags=c()}
def get_videoset_features() -> list:
    '''Get the VQA dataset video names and scores, set a feature extractor model,
       get frames of each video, then get features of each frame in videos
       
    :return: videos' frames features of dimension and videos scores (DMOS)
    '''
    
    # put the metadata file path of the LIVE VQA dataset
    video_data = '/media/amirh/Programs/Projects/VQA_Datasets/LIVE_SD/live_video_quality_seqs.txt'
    dmos_data = '/media/amirh/Programs/Projects/VQA_Datasets/LIVE_SD/live_video_quality_data.txt'
    videos_dir = Path('/media/amirh/Programs/Projects/VQA_Datasets/LIVE_SD')
    
    # Get the list of videos and corresponding dmos and preprocessing module
    video_list, dmos, transform = dh.prepare_videoset(dataset='LIVE', frame_size=254,
                                                  video_file=video_data, dmos_file=dmos_data)
    
    # Check if there is a GPU
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Set the frame features extractor model (VGG19)
    model = sfv.set_sf_model(device)
    
    videos_frame_features = []
    for seq in video_list:
        # Concatenate the video sequence name to the video directory to get the full video path
        vid_path = str(videos_dir / seq)
        # Get frames of the video of the dimension 768 * 432 (LIVE VQA videos)
        vid_frames = vu.get_frames(vid_path, height=432, width=768)
        # Get the features of all frames of the video
        frames_features = np.array(sfv.get_video_style_features(vid_frames, model, device, transform))
        videos_frame_features.append(frames_features)
    
    return videos_frame_features, dmos
```

```{python}
# Entry point of the program
def main():
    # Get frame level features of all videos in the dataset
    videos_feats, dmos= get_videoset_features()
    # Pool the frame level features to get video level features
    pooled_features = pooling.simple_pooling(videos_feats)
    # Train a regressor using video level features and indicate how well it predicts the scores
    # using various correlations
    reg.live_dataset_regression(pooled_features, dmos)
    
```

```{python tags=c()}
# Run the main function if current file is the script, not a module
if __name__ == "__main__":
    main()
```

```{python}

```
